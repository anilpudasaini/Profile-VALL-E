{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b02a756f-d2fb-46d8-a9de-7cdab44bee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/anil/valle_tts_profile_project')\n",
    "sys.path = [p for p in sys.path if p not in ['/home/anil/USLM', '/home/anil/icefall']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc999d78-cfb6-4807-a75e-f575f7961177",
   "metadata": {},
   "source": [
    "### AudioTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08713325-06dc-4310-94bd-24ace2523405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data.tokenizer import AudioTokenizer, tokenize_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a123e99-c938-4bfa-ac12-0dc0c43c2cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "#path\n",
    "audio_file_path = '/home/anil/sample_audios/sample_with_birds.wav'\n",
    "\n",
    "#instance of AudioTokenizer\n",
    "audio_tokenizer = AudioTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a68708-5742-4b83-b005-0a3e7dd97429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([[[ 738,  834, 1017,  ...,  133, 1017,  738],\n",
      "         [ 364,  743,  974,  ...,  937,  277,  302],\n",
      "         [ 531,  868,  618,  ...,  196, 1000,   36],\n",
      "         ...,\n",
      "         [ 939,  768,   19,  ...,  768,  939,  412],\n",
      "         [ 782,  944,  860,  ..., 1015, 1015,  772],\n",
      "         [ 467,  884,  583,  ...,  931,  701,  899]]], device='cuda:0'), None)]\n"
     ]
    }
   ],
   "source": [
    "encoded_frames = tokenize_audio(audio_tokenizer, audio_file_path)\n",
    "print(encoded_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3914ce46-5439-4c68-b561-e2f76dc52eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 531])\n",
      "torch.Size([1, 7, 531])\n"
     ]
    }
   ],
   "source": [
    "#taking only the output of first quantizer\n",
    "q1 = encoded_frames[0][0][:,:2,:] #batch, n_Q, timesteps\n",
    "q2_8 = encoded_frames[0][0][:,1:10,:] #batch, n_Q, timesteps\n",
    "print(q1.shape), print(q2_8.shape)\n",
    "q1 = [(q1, None)] #model.decode expects a tuple with codes and scale.\n",
    "q2_8 = [(q2_8, None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0970ef16-0cf5-422b-99c2-eca564c6b5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 531])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1)  # [B, n_q, T]\n",
    "#codes matrices\n",
    "codes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3268a170-11e4-41fe-9ed8-5c7c430214c8",
   "metadata": {},
   "source": [
    "### Phonemizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3377de78-fc7e-4b23-9c72-65e858ea0c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'həlˈoʊ wˈɜːld'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.grapheme2phoneme import encode as phonemize\n",
    "tokens = phonemize(\"Hello World\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb776246-0da6-4c43-ac02-21cc7afd05cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wˈʌn', 'tˈuː', 'θɹˈiː']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonemize(\"1 2 3\").split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99850dfe-4a05-4698-991b-ad4820baf9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dˈɑːɡz', 'ɑːɹ', 'sˈɪɾɪŋ', 'æt', 'ðə', 'dˈoːɹ']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonemes = phonemize(\"dogs are sitting at the door\").split(' ')\n",
    "phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bed8c8d-7e73-4118-9766-7867310f68f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (encodec)",
   "language": "python",
   "name": "encodec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
