2024-11-11 05:41:51,001 INFO [trainer.py:870] Training started
2024-11-11 05:41:51,005 INFO [trainer.py:889] Device: cuda:0
2024-11-11 05:41:51,005 INFO [trainer.py:890] {'best_train_loss': inf, 'best_valid_loss': inf, 'best_train_epoch': -1, 'best_valid_epoch': -1, 'batch_idx_train': 0, 'log_interval': 100, 'reset_interval': 200, 'valid_interval': 20000, 'env_info': {'k2-version': '1.24.3', 'k2-build-type': 'Release', 'k2-with-cuda': True, 'k2-git-sha1': 'e400fa3b456faf8afe0ee5bfe572946b4921a3db', 'k2-git-date': 'Sat Jul 15 04:21:50 2023', 'lhotse-version': '1.28.0.dev+git.9648516.clean', 'torch-version': '1.13.1+cu116', 'torch-cuda-available': True, 'torch-cuda-version': '11.6', 'python-version': '3.10', 'icefall-git-branch': 'main', 'icefall-git-sha1': 'a9721a6-dirty', 'icefall-git-date': 'Sat Nov 9 12:57:08 2024', 'icefall-path': '/home/anil/icefall', 'k2-path': '/home/anil/miniconda3/envs/lifeiteng/lib/python3.10/site-packages/k2/__init__.py', 'lhotse-path': '/home/anil/miniconda3/envs/lifeiteng/lib/python3.10/site-packages/lhotse/__init__.py', 'hostname': 'b-hp-gpu1', 'IP address': '192.168.200.20'}, 'world_size': 1, 'master_port': 12354, 'tensorboard': True, 'num_epochs': 20, 'start_epoch': 1, 'start_batch': 0, 'exp_dir': PosixPath('exp/valle/AR_light'), 'optimizer_name': 'ScaledAdam', 'scheduler_name': 'Eden', 'base_lr': 0.05, 'warmup_steps': 200, 'seed': 42, 'inf_check': False, 'save_every_n': 10000, 'keep_last_k': 20, 'average_period': 0, 'accumulate_grad_steps': 4, 'dtype': 'bfloat16', 'filter_min_duration': 0.5, 'filter_max_duration': 14.0, 'train_stage': 1, 'visualize': False, 'oom_check': True, 'model_name': 'valle', 'decoder_dim': 512, 'nhead': 8, 'num_decoder_layers': 6, 'scale_factor': 1.0, 'norm_first': True, 'add_prenet': False, 'prefix_mode': 1, 'share_embedding': True, 'prepend_bos': False, 'num_quantizers': 8, 'scaling_xformers': False, 'manifest_dir': PosixPath('data/tokenized'), 'max_duration': 80, 'bucketing_sampler': True, 'num_buckets': 6, 'concatenate_cuts': False, 'duration_factor': 1.0, 'gap': 0.1, 'on_the_fly_feats': False, 'shuffle': True, 'buffer_size': 40000, 'shuffle_buffer_size': 100000, 'drop_last': False, 'return_cuts': True, 'num_workers': 8, 'enable_spec_aug': False, 'spec_aug_time_warp_factor': 80, 'input_strategy': 'PrecomputedFeatures', 'dataset': 'libritts', 'text_tokens': 'data/tokenized/unique_text_tokens.k2symbols', 'sampling_rate': 24000}
2024-11-11 05:41:51,005 INFO [trainer.py:892] About to create model
2024-11-11 05:41:51,337 INFO [trainer.py:899] Number of model parameters: 50956292
2024-11-11 05:41:53,670 INFO [datamodule.py:427] About to get train cuts
